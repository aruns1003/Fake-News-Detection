This project focuses on fake news detection using two different approaches:

A classical Machine Learning baseline with TF-IDF vectorization + Logistic Regression.

A state-of-the-art Deep Learning model using DistilBERT fine-tuned for sequence classification.

By comparing both approaches, the project highlights the trade-off between speed, simplicity, and interpretability (Logistic Regression) vs. accuracy and semantic understanding (DistilBERT).

üìÇ Dataset

Source: Kaggle ‚Äì Fake and Real News Dataset

Two CSV files:

Fake.csv ‚Üí Fake news articles

True.csv ‚Üí Real news articles

Labels added:

0 ‚Üí Fake

1 ‚Üí True

‚öôÔ∏è Methods
1Ô∏è‚É£ Logistic Regression (Baseline)

Preprocessing:

Convert text into TF-IDF features.

Limit features with stop_words='english' and max_df=0.7.

Classifier: Logistic Regression.

Pros:

Extremely fast, interpretable.

Works surprisingly well with textual data.

Cons:

Ignores word context/semantics.

Struggles with subtle differences in language.

2Ô∏è‚É£ DistilBERT (Deep Learning)

Preprocessing:

Tokenization with Hugging Face DistilBertTokenizerFast.

Sequences padded/truncated to fixed length.

Model: DistilBERT fine-tuned with classification head (num_labels=2).

Training: AdamW optimizer, cross-entropy loss, trained for 2 epochs.

Pros:

Captures semantic meaning & context.

Achieves state-of-the-art accuracy.

Cons:

Computationally expensive (hours on CPU, faster on GPU).

Black-box nature makes it less interpretable.

üìä Results
Model	Precision	Recall	F1-score	Accuracy	Training Time
Logistic Regression (TF-IDF)	~0.98	~0.98	~0.98	98%	‚ö° Seconds
DistilBERT	1.00	1.00	1.00	100%	üê¢ ~7h (CPU)

Key Insight:

Logistic Regression is fast, lightweight, and already very accurate.

DistilBERT achieves perfect results but at a heavy computational cost.

Depending on resources and needs, Logistic Regression may be preferable for quick deployment, while DistilBERT is best for maximum accuracy.
